{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25cbc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e64c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB_reviews_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d287e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40b39099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24882\n",
       "1    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4462dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['clean_review'], sample_df['sentiment'], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a58546",
   "metadata": {},
   "source": [
    "## Embedding Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63df5a60",
   "metadata": {},
   "source": [
    "#### TF-IDF Embedding with SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dfdf58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with TF-IDF Embedding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       151\n",
      "           1       0.82      0.72      0.77       149\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.79      0.78      0.78       300\n",
      "weighted avg       0.79      0.78      0.78       300\n",
      "\n",
      "Accuracy: 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1500)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "svm_tfidf = SVC()\n",
    "svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"SVM with TF-IDF Embedding:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce3067",
   "metadata": {},
   "source": [
    "#### Word2Vec Embedding with SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a49ce675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Word2Vec Embedding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.13      0.22       151\n",
      "           1       0.51      0.92      0.66       149\n",
      "\n",
      "    accuracy                           0.52       300\n",
      "   macro avg       0.57      0.53      0.44       300\n",
      "weighted avg       0.57      0.52      0.44       300\n",
      "\n",
      "Accuracy: 0.5233333333333333\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "tokenized_reviews = [review.split() for review in X_train]\n",
    "\n",
    "\n",
    "word2vec = Word2Vec(sentences=tokenized_reviews, vector_size=500, window=5, min_count=1)\n",
    "\n",
    "\n",
    "def document_embedding(doc, model):\n",
    "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(500)\n",
    "\n",
    "\n",
    "X_train_w2v = np.array([document_embedding(doc.split(), word2vec) for doc in X_train])\n",
    "X_test_w2v = np.array([document_embedding(doc.split(), word2vec) for doc in X_test])\n",
    "\n",
    "\n",
    "svm_w2v = SVC()\n",
    "svm_w2v.fit(X_train_w2v, y_train)\n",
    "y_pred_w2v = svm_w2v.predict(X_test_w2v)\n",
    "\n",
    "\n",
    "print(\"SVM with Word2Vec Embedding:\")\n",
    "print(classification_report(y_test, y_pred_w2v))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b134406",
   "metadata": {},
   "source": [
    "#### GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb2d6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with GloVe Embedding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       151\n",
      "           1       0.74      0.71      0.73       149\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n",
      "Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glove_file = \"glove.6B.100d.txt\"\n",
    "glove_embeddings = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "def document_embedding_glove(doc, embeddings):\n",
    "    vectors = [embeddings[word] for word in doc if word in embeddings]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "X_train_glove = np.array([document_embedding_glove(doc.split(), glove_embeddings) for doc in X_train])\n",
    "X_test_glove = np.array([document_embedding_glove(doc.split(), glove_embeddings) for doc in X_test])\n",
    "\n",
    "svm_glove = SVC()\n",
    "svm_glove.fit(X_train_glove, y_train)\n",
    "y_pred_glove = svm_glove.predict(X_test_glove)\n",
    "\n",
    "print(\"SVM with GloVe Embedding:\")\n",
    "print(classification_report(y_test, y_pred_glove))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_glove))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d0685",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "From the above we can see that the TF-IDF embedding is performing best with the dataset so we are gonna go ahed and train our models using the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4183637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
